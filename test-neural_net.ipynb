{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # wih : Weight Input Hidden\n",
    "        # wih : Weight Output Hidden\n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "train_data_file = open(\"G:/data/mnist_dataset/emnist-balanced-train.csv\", 'r')\n",
    "train_data_list = train_data_file.readlines()\n",
    "train_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"G:/data/mnist_dataset/emnist-balanced-test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b963748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEOlJREFUeJzt3X2IXfWdx/HPNxPNU2N8mEkarWlM\no6sxEpWLClnWiKTEoMT+UTFgzYKYIhVXaGBVkCq4IMvWrn9IYbqGRrC2Qmt8CtogK66wJhljfOga\ntyYk7ZiHmfgYzZNJvvvH3HRHnfv93dxz7z138nu/QGbmfu+Z881xPnPu3N85v5+5uwDkZ0zZDQAo\nB+EHMkX4gUwRfiBThB/IFOEHMkX4gUwRfiBThB/I1Nh27qy7u9tnzpzZzl0CWdm2bZv27Nlj9Ty3\nUPjNbJGkhyV1SfoPd38wev7MmTPV19dXZJcAApVKpe7nNvyy38y6JD0i6RpJcyQtNbM5jX4/AO1V\n5G/+yyS97+5b3f2QpN9KWtKctgC0WpHwnyXpr8O+7q8+9hVmttzM+sysb3BwsMDuADRTkfCP9KbC\nN+4Pdvded6+4e6Wnp6fA7gA0U5Hw90s6e9jX35G0o1g7ANqlSPg3SDrXzM4xs5Ml3Sjpmea0BaDV\nGh7qc/fDZna7pBc1NNS30t3/1LTOALRUoXF+d18jaU2TegHQRlzeC2SK8AOZIvxApgg/kCnCD2SK\n8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SqrVN3ozGHDx8O659//nnN2tGjR8Ntx48fX6g+\nZgznj9GK/3NApgg/kCnCD2SK8AOZIvxApgg/kCnCD2SKcf4O4P6NhY6+IhrHl6QXXnihZm3v3r3h\ntvPmzQvrF154YVifOHFiWDera7Xotktd/5CS+nd16r97OM78QKYIP5Apwg9kivADmSL8QKYIP5Ap\nwg9kqtA4v5ltk7RX0hFJh9290oymcrNv376w/sADD4T13t7emrWDBw+G23Z3d4f1m2++Oazfe++9\nYX3ChAk1a0XHwovMcxBdGyFJn332WVivVOIf9VmzZoX1KVOm1Ky16xqBZlzkc5W772nC9wHQRrzs\nBzJVNPwu6Y9m9rqZLW9GQwDao+jL/vnuvsPMpkpaa2ab3f2V4U+o/lJYLkkzZswouDsAzVLozO/u\nO6ofByQ9JemyEZ7T6+4Vd6/09PQU2R2AJmo4/GY2ycwmH/tc0vclvdOsxgC0VpGX/dMkPVUdlhgr\n6TfuHo+fAOgYDYff3bdKim8Gz0TqfvwDBw6E9ccff7xQPXW/f2Tnzp1hPTUevmLFirAezftfdDy7\nyDwHt912W7ht6tqL8847L6wvWrQorN9///01a6k5EpqFoT4gU4QfyBThBzJF+IFMEX4gU4QfyBRT\ndzdBaqgvdevpunXrwvqnn3563D01y5EjR8J6agrs1LEpItVbdFtuaijvyy+/DOvbt28P6xs3bgzr\nhw4dqlljqA9ASxF+IFOEH8gU4QcyRfiBTBF+IFOEH8gU4/xNMGZM/Ds0mr5akhYvXhzWV69eHdaj\nW4ZT4+yp22pTU1gPDAyE9cmTJ9esdXV1hdumpK4xiMbqi15/kLoOIHVtRuoahXbgzA9kivADmSL8\nQKYIP5Apwg9kivADmSL8QKYY52+C1Jhxqr5r166wnpr6u5VS1yhES01L0tixjf+IpY7b1q1bw/qb\nb75Zs5a6RiB17cZ1110X1q+66qqw3q579iOc+YFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyFRyENbM\nVkq6VtKAu8+tPna6pN9Jmilpm6Qb3P3j1rXZ2fbv3x/WN2/eHNYfeeSRQt+/lU466aSwnroOIDVe\nHkmN80fj+JK0YcOGmrXUOH9qHH7JkiVh/ZprrgnrqePWDvX8n/m1pK8vNn6XpJfc/VxJL1W/BjCK\nJMPv7q9I+uhrDy+RtKr6+SpJ1ze5LwAt1uhrsmnuvlOSqh+nNq8lAO3Q8jf8zGy5mfWZWd/g4GCr\ndwegTo2Gf7eZTZek6seaszi6e6+7V9y90tPT0+DuADRbo+F/RtKy6ufLJD3dnHYAtEsy/Gb2hKT/\nlvR3ZtZvZrdIelDSQjP7s6SF1a8BjCLJcX53X1qjdHWTexm1Dh48GNZT4/z9/f2F9l90DvpOlfp3\npebOLzI3/imnnBLWZ8+eHdbHjx/f8L7bhSv8gEwRfiBThB/IFOEHMkX4gUwRfiBTTN1dp8OHD9es\nbdy4Mdx27dq1YX3fvn0N9XSiSw2hpm7p3bNnT8P77u7uDuuzZs0K6+PGjWt43+3CmR/IFOEHMkX4\ngUwRfiBThB/IFOEHMkX4gUwxzl+Vun30rbfeqlm78847w21TS0mnppEu85bd1Fh76hqF6NbY1LTe\nqe+9fv36sP7hhx+G9UhXV1dYT/VuZg3vu1048wOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnG+atS\nY+nR9Nvbt28Ptz1w4EBDPR1T5pjx3r17w/qOHTvC+hlnnFGzllr+O7U0eape5PqI0047LaynrgMY\nDTjzA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QqeQ4v5mtlHStpAF3n1t97D5Jt0oarD7tHndf06om\n2yE1Zvzyyy/XrKXuOy96P/6ECRPC+sknn1yz9sUXX4TbRusRSOl74lNz50dLWaeWsX711VfD+gcf\nfBDWo3/b2LHxj/6iRYvC+qRJk8J66n7/TlBPh7+WNNKR+IW7X1z9b1QHH8hRMvzu/oqkj9rQC4A2\nKvLa5HYze8vMVppZfC0kgI7TaPh/Kel7ki6WtFPSz2s90cyWm1mfmfUNDg7WehqANmso/O6+292P\nuPtRSb+SdFnw3F53r7h7paenp9E+ATRZQ+E3s+nDvvyBpHea0w6AdqlnqO8JSQskdZtZv6SfSVpg\nZhdLcknbJP24hT0CaIFk+N196QgPP9qCXloqNZ69bt26sP7888/XrKXm3U+ZOnVqWF+xYkVY37Vr\nV83a6tWrw21TawqkrlH4+OOPw3p0DcSpp54abvvJJ5+E9UOHDoX1SHd3d1i/8sorw3rqOoHRoPOv\nRADQEoQfyBThBzJF+IFMEX4gU4QfyNToH6+oSg1JpYaF1qyJb0xMDWkVkZomevHixWH9xRdfrFlL\n3Q6ckhrG3LJlS1iPpvaePn16zVo9+y5i8uTJYf3MM88M66NhCe4UzvxApgg/kCnCD2SK8AOZIvxA\npgg/kCnCD2TqhBnnLzoFdWqcP1pmOzXmm5qi+tprrw3rM2bMCOvRNNJFbz1NjbWvX78+rF9yySU1\naxdccEG47aZNm8J6kesAJk6cWKh+IuDMD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxApkbVOH90z35q\nKbBnn302rG/fvr2hnqT01Nup5Z7vvvvusJ4ac65UKjVrV199dbjte++9F9aj6xskaffu3WH9tdde\nq1k75ZRTwm1T116kxvm7urpq1q644opw26LzIIwGnPmBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8hU\ncpzfzM6W9Jikb0s6KqnX3R82s9Ml/U7STEnbJN3g7q2b3F7S/v37a9YeeuihcNvUmHH0vaX4nv05\nc+aE2y5cuDCsp5aqHjMm/h09d+7cmrU77rgj3DZ1XDZv3hzWBwYGwvqTTz5Zs/bcc8+F26aW6E5d\n/3DOOefUrN1yyy3htqk5GE4E9Zz5D0v6qbtfIOkKST8xszmS7pL0krufK+ml6tcARolk+N19p7tv\nrH6+V9K7ks6StETSqurTVkm6vlVNAmi+4/qb38xmSrpE0jpJ09x9pzT0C0JSfI0rgI5Sd/jN7FuS\nfi/pTnf/7Di2W25mfWbWl7r+HkD71BV+MztJQ8F/3N3/UH14t5lNr9anSxrxnR9373X3irtXenp6\nmtEzgCZIht+G3uZ+VNK77j78LfVnJC2rfr5M0tPNbw9Aq9RzS+98ST+S9LaZHZtL+R5JD0p60sxu\nkfQXST9sTYv/L1pm+4033gi37e/vL7TvaOjn0ksvDbc9//zzw3rR5Z6j6blTS1FPmzYtrKeG+lJL\nox88eLBmLbVsemqIMxrKk+LbmWfPnl1o3yeCZPjd/VVJtX4645vFAXSsE//XG4AREX4gU4QfyBTh\nBzJF+IFMEX4gU6Nq6u4jR47UrKWW4E4t4T1u3LiwfuONN9aspabeTk1RXXScPxqTTo3z33TTTWF9\ny5YtYT01dXeku7s7rKeWLr/11lvDejSWP2XKlHDbHHDmBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4g\nU6NqnD9acvnyyy8Pt50/f35Yv+iii8L6ggULataKTr3dStG9/pK0dOnSsJ46Lps2bQrrkXnz5oX1\naEpyKb2Mdg735BfB0QEyRfiBTBF+IFOEH8gU4QcyRfiBTBF+IFOWmne9mSqVivf19TW8fXQ//759\n+8Jto2sEpPT9/NGYcdH78TtZ6uejyM9P6ridyMe1VSqVivr6+uo6cJz5gUwRfiBThB/IFOEHMkX4\ngUwRfiBThB/IVPJ+fjM7W9Jjkr4t6aikXnd/2Mzuk3SrpMHqU+9x9zWtalSKx+onTZoUbsuYcmM4\nbieueibzOCzpp+6+0cwmS3rdzNZWa79w939rXXsAWiUZfnffKWln9fO9ZvaupLNa3RiA1jquv/nN\nbKakSyStqz50u5m9ZWYrzey0GtssN7M+M+sbHBwc6SkASlB3+M3sW5J+L+lOd/9M0i8lfU/SxRp6\nZfDzkbZz9153r7h7paenpwktA2iGusJvZidpKPiPu/sfJMndd7v7EXc/KulXki5rXZsAmi0Zfht6\nO/dRSe+6+0PDHp8+7Gk/kPRO89sD0Cr1vNs/X9KPJL1tZsfmab5H0lIzu1iSS9om6cct6bBOTNMM\nHJ963u1/VdJIg7ktHdMH0FqcLoFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU4Qf\nyBThBzJF+IFMEX4gU21dotvMBiVtH/ZQt6Q9bWvg+HRqb53al0RvjWpmb99197rmy2tr+L+xc7M+\nd6+U1kCgU3vr1L4kemtUWb3xsh/IFOEHMlV2+HtL3n+kU3vr1L4kemtUKb2V+jc/gPKUfeYHUJJS\nwm9mi8zsPTN738zuKqOHWsxsm5m9bWabzKyv5F5WmtmAmb0z7LHTzWytmf25+nHEZdJK6u0+M/ug\neuw2mdnikno728z+08zeNbM/mdk/VR8v9dgFfZVy3Nr+st/MuiT9r6SFkvolbZC01N3/p62N1GBm\n2yRV3L30MWEz+wdJn0t6zN3nVh/7V0kfufuD1V+cp7n7P3dIb/dJ+rzslZurC8pMH76ytKTrJf2j\nSjx2QV83qITjVsaZ/zJJ77v7Vnc/JOm3kpaU0EfHc/dXJH30tYeXSFpV/XyVhn542q5Gbx3B3Xe6\n+8bq53slHVtZutRjF/RVijLCf5akvw77ul+dteS3S/qjmb1uZsvLbmYE06rLph9bPn1qyf18XXLl\n5nb62srSHXPsGlnxutnKCP9Iq/900pDDfHe/VNI1kn5SfXmL+tS1cnO7jLCydEdodMXrZisj/P2S\nzh729Xck7SihjxG5+47qxwFJT6nzVh/efWyR1OrHgZL7+ZtOWrl5pJWl1QHHrpNWvC4j/BsknWtm\n55jZyZJulPRMCX18g5lNqr4RIzObJOn76rzVh5+RtKz6+TJJT5fYy1d0ysrNtVaWVsnHrtNWvC7l\nIp/qUMa/S+qStNLd/6XtTYzAzGZp6GwvDS1i+psyezOzJyQt0NBdX7sl/UzSaklPSpoh6S+Sfuju\nbX/jrUZvCzT00vVvKzcf+xu7zb39vaT/kvS2pKPVh+/R0N/XpR27oK+lKuG4cYUfkCmu8AMyRfiB\nTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8jU/wEGGzsQ/okG1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b90f6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "all_values = train_data_list[42].split(',')\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "\n",
    "matplotlib.pyplot.imshow(np.transpose(image_array), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "input_nodes = len(all_values)-1\n",
    "hidden_nodes = 250\n",
    "output_nodes = 47\n",
    "print(input_nodes)\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put train_data_list into numerical values\n",
    "# and creating features/labels lists\n",
    "features_train_list = []\n",
    "labels_train_list = []\n",
    "for record in train_data_list:\n",
    "        # split the record by the ','\n",
    "        all_values = record.split(',')\n",
    "        \n",
    "        feature = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # store it in a list\n",
    "        features_train_list.append(feature) \n",
    "\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_record[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        \n",
    "        labels_train_list.append(targets)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same with test dataset\n",
    "features_test_list = []\n",
    "labels_test_list = []\n",
    "for record in test_data_list:  \n",
    "        all_values = record.split(',')\n",
    "        feature = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        features_test_list.append(feature) \n",
    "        \n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "\n",
    "        labels_test_list.append(targets)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neuronal network\n",
    "epochs = 3\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for i, elt in enumerate(features_test_list):\n",
    "        n.train(features_test_list[i], labels_test_list[i])\n",
    "        \n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "label_pred = []\n",
    "label_true = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for i, record in enumerate(features_test_list):\n",
    "    # query the network\n",
    "    outputs = n.query(features_test_list[i])\n",
    "\n",
    "    # the index of the highest value corresponds to the label    \n",
    "    label_pred.append(np.argmax(outputs))\n",
    "    label_true.append(np.argmax(labels_test_list[i]))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326   0   0 ...   0   0   1]\n",
      " [  0 260   0 ...   0   1   6]\n",
      " [  1   0 307 ...   2   0   0]\n",
      " ...\n",
      " [  1   0   0 ... 123   1   2]\n",
      " [  1   0   0 ...   1 360   6]\n",
      " [  0   0   0 ...   0  11 327]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate Confusion matrix\n",
    "conf_matrix = confusion_matrix(label_true, label_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815  0.65   0.7675 0.945  0.7875 0.9075 0.8475 0.895  0.86   0.885\n",
      " 0.9025 0.9025 0.7825 0.855  0.8375 0.7425 0.8475 0.8475 0.5075 0.8475\n",
      " 0.8425 0.4725 0.9525 0.8175 0.4425 0.8475 0.895  0.7925 0.565  0.89\n",
      " 0.875  0.8975 0.98   0.905  0.825  0.84   0.5475 0.9325 0.925  0.885\n",
      " 0.4775 0.5425 0.8575 0.835  0.3075 0.9    0.8175]\n",
      "lowest classified group:  44\n",
      "highest classified group:  32\n"
     ]
    }
   ],
   "source": [
    "# Calculate perfomance per label\n",
    "perf_matrix = np.diag(conf_matrix)/conf_matrix.sum(axis=1)\n",
    "print(perf_matrix)\n",
    "print(\"Lowest classified group: \", np.argmin(perf_matrix))\n",
    "print(\"Highest classified group: \", np.argmax(perf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.7936170212765957\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score\n",
    "print(\"performance = \", sum(np.diag(conf_matrix))/ conf_matrix.sum() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
